{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kaggle_code.py","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ViStHcuPJQM7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ce4306e3-23e0-4b59-e2c7-6115dd22de2e"},"source":["import os\n","import numpy as np\n","import cv2\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","\n","this_path = '/content/drive/My Drive/Colab Notebooks/'\n","\n","\n","class Data:\n","    def __init__(self, batch_size):\n","        self.in_ht, self.in_wd = 240, 320\n","        self.create_stat_image = False\n","        self.out_ht, self.out_wd = int(self.in_ht / 2), int(self.in_wd / 2)\n","        self.vld_portion = 0.1\n","        self.batch_size = {'TRAIN': batch_size, 'VALIDATION': batch_size, 'TEST': 1}\n","        self.in_dir = os.path.join(this_path, 'images')\n","\n","        self.id2cell = pd.Series(os.listdir(os.path.join(self.in_dir, 'TRAIN')))\n","        self.cell2id = pd.Series(range(len(self.id2cell)), index=self.id2cell)\n","\n","        self.x_trn_list, self.x_vld_list, self.y_trn, self.y_vld = self._get_names_labels(phase='TRAIN')\n","        self.x_tst_list, self.y_tst = self._get_names_labels(phase='TEST')\n","        self.steps_per_epoch = int(np.ceil(len(self.x_trn_list)/self.batch_size['TRAIN']))\n","        self.validation_steps = int(np.ceil(len(self.x_vld_list)/self.batch_size['TRAIN']))\n","        self.test_steps = int(np.ceil(len(self.x_tst_list)/self.batch_size['TEST']))\n","\n","        # self.mean_img, self.std_img = self._get_stat_images()\n","\n","    def _get_names_labels(self, phase):\n","        if phase not in ('TRAIN', 'TEST'):\n","            raise self.DataInitError(\"Error: 'phase' must be either of 'TRAIN' or 'TEST'\")\n","\n","        in_dir = os.path.join(self.in_dir, phase)\n","        if not os.path.exists(in_dir):\n","            raise self.DataInitError('Error: Directory {:s} does not exist.'.format(in_dir))\n","\n","        x = list()\n","        labels = dict()\n","        for cell_id in self.id2cell.index:\n","            img_dir = os.path.join(in_dir, self.id2cell[cell_id])\n","            img_names = [a for a in os.listdir(img_dir) if a.endswith('.jpeg')]\n","            img_paths = [os.path.join(img_dir, img_name) for img_name in img_names]\n","            x += img_paths\n","            labels[cell_id] = np.zeros([len(img_paths), len(self.id2cell)], dtype=bool)  # One hot vector\n","            labels[cell_id][:, cell_id] = True\n","\n","        y = np.concatenate([labels[a] for a in self.id2cell.index])\n","\n","        if phase == 'TRAIN':\n","            trn_x_list, vld_x_list, y_trn, y_vld = \\\n","                train_test_split(x, y, test_size=self.vld_portion, random_state=42, stratify=y, shuffle=True)\n","\n","            return trn_x_list, vld_x_list, y_trn, y_vld\n","        else:\n","            return x, y\n","\n","    def _normalize_image(self, img_in):\n","        if 0:  # 100_4_10\n","            # Unnormalized\n","            img = img_in\n","        elif 0:  # 100_4_11\n","            # Normalize each image independently\n","            img = np.empty(img_in.shape, dtype=img_in.dtype)\n","            assert(img_in.shape[2] == 3)\n","            for i in range(img_in.shape[2]):  # Loop over channels\n","                # Within an image, normalize each channel independently\n","                img[:, :, i] = (img_in[:, :, i] - img_in[:, :, i].mean()) / img_in[:, :, i].std()\n","        else:  # 100_4_12\n","            # Just scale range (0, 255) to (-1, +1)\n","            img = img_in/255. - 0.5\n","        #else:  # 100_4\n","            # Default: Normalize each dimension\n","            # img = (img_in - self.mean_img) / self.std_img\n","\n","        return img\n","\n","    def get_batch(self, phase):\n","        if phase not in ('TRAIN', 'TEST', 'VALIDATION'):\n","            raise self.DataBatchError(\"Error: 'phase' must be either of 'TRAIN', 'TEST' or 'VALIDATION\")\n","\n","        if phase == 'TRAIN':\n","            x_list = self.x_trn_list\n","            y = self.y_trn\n","        elif phase == 'VALIDATION':\n","            x_list = self.x_vld_list\n","            y = self.y_vld\n","        else:\n","            x_list = self.x_tst_list\n","            y = self.y_tst\n","\n","        # Allocated one-time memory for the batch\n","        x_batch = np.zeros((self.batch_size[phase], self.out_ht, self.out_wd, 3), dtype=float)\n","        y_batch = np.zeros((self.batch_size[phase], len(self.cell2id)), dtype=bool)\n","\n","        src_idx = 0\n","        dst_idx = 0\n","        while True:\n","            img_path = x_list[src_idx]\n","            img = cv2.imread(img_path)\n","            if img is None:\n","                raise self.DataBatchError(\"Error: Can't open image: {:s}\".format(img_path))\n","\n","            img = cv2.resize(img, (self.out_wd, self.out_ht)).astype(float)\n","\n","            # Normalize the image\n","            img = self._normalize_image(img)\n","\n","            x_batch[dst_idx] = img\n","            y_batch[dst_idx] = y[src_idx]\n","            src_idx += 1\n","            dst_idx += 1\n","\n","            if src_idx >= len(x_list):\n","                src_idx = 0\n","\n","            if dst_idx >= self.batch_size[phase]:\n","                dst_idx = 0\n","                yield x_batch.copy(), y_batch.copy()\n","\n","    def _get_stat_images(self):\n","        mean_img_path = os.path.join(this_path, 'resources', 'mean_image_{:d}x{:d}.npy'.format(self.out_wd, self.out_ht))\n","        std_img_path = os.path.join(this_path, 'resources', 'std_image_{:d}x{:d}.npy'.format(self.out_wd, self.out_ht))\n","\n","        if self.create_stat_image:\n","            print(\"Creating Mean and Std images... \")\n","            x_train = np.empty((len(self.x_trn_list), self.out_ht, self.out_wd, 3), dtype=np.uint8)\n","            for idx, img_path in enumerate(self.x_trn_list):\n","                img = cv2.imread(img_path)\n","                if img is None:\n","                    raise self.DataInitError(\"Error: Can't open image: {:s}\".format(img_path))\n","\n","                img = cv2.resize(img, (self.out_wd, self.out_ht))\n","                x_train[idx] = img\n","\n","            mean_img = x_train.mean(axis=0)\n","            std_img = x_train.std(axis=0)\n","            np.save(mean_img_path, mean_img)\n","            np.save(std_img_path, std_img)\n","            # Dump images as well for verification purposes\n","            cv2.imwrite(mean_img_path.replace('.npy', '.png'), mean_img.astype(np.uint8))\n","            cv2.imwrite(std_img_path.replace('.npy', '.png'), std_img.astype(np.uint8))\n","\n","            print('Done writing mean and std images. ')\n","\n","        mean_img = np.load(mean_img_path)\n","        std_img = np.load(std_img_path)\n","        return mean_img, std_img\n","\n","    def read_dir(self, dir_path, id2cell, stat_imgs=None):\n","        if not os.path.exists(dir_path):\n","            raise self.DataInitError('Error: Directory {:s} does not exist.'.format(dir_path))\n","\n","        imgs = dict()\n","        labels = dict()\n","\n","        if stat_imgs is not None:\n","            mean_img = stat_imgs[0]\n","            std_img = stat_imgs[1]\n","\n","        for id in id2cell.index:\n","            img_dir = os.path.join(dir_path, id2cell[id])\n","            img_names = [x for x in os.listdir(img_dir) if x.endswith('.jpeg')]\n","            imgs[id] = np.zeros([len(img_names), self.out_ht, self.out_wd, 3], dtype=float)\n","\n","            for i, img_name in enumerate(img_names):\n","                img = cv2.imread(os.path.join(img_dir, img_name))\n","                assert(img is not None)\n","                img = cv2.resize(img, (self.out_wd, self.out_ht)).astype(float)\n","                if stat_imgs is not None:  # Normalizing images\n","                    img = (img - mean_img)/std_img\n","                imgs[id][i, :, :, :] = img\n","\n","            labels[id] = np.zeros([len(imgs[id]), len(id2cell)], dtype=bool)  # One hot vector\n","            labels[id][:, id] = True\n","\n","        x = np.concatenate([imgs[a] for a in id2cell.index])\n","        y = np.concatenate([labels[a] for a in id2cell.index])\n","        return x, y\n","\n","    def load_data(self, create_stat_image=False):\n","\n","        in_dir = os.path.join(this_path, 'dataset', 'dataset2-master', 'images')\n","\n","        id2cell = pd.Series(os.listdir(os.path.join(in_dir, 'TRAIN')))\n","        cell2id = pd.Series(range(len(id2cell)), index=id2cell)\n","\n","        mean_img_path = os.path.join(this_path, 'resources', 'mean_image_{:d}x{:d}.npy'.format(self.out_wd, self.out_ht))\n","        std_img_path = os.path.join(this_path, 'resources', 'std_image_{:d}x{:d}.npy'.format(self.out_wd, self.out_ht))\n","\n","        if create_stat_image:\n","            x_train, y_train = self.read_dir(os.path.join(in_dir, 'TRAIN'), id2cell)\n","            x_test, y_test = self.read_dir(os.path.join(in_dir, 'TEST'), id2cell)\n","\n","            x_train, x_validation, y_train, y_validation = \\\n","                train_test_split(x_train, y_train, test_size=self.vld_portion, random_state=42, stratify=y_train)\n","\n","            mean_img = x_train.mean(axis=0)\n","            std_img = x_train.std(axis=0)\n","            print('Writing mean and std images.. ')\n","            np.save(mean_img_path, mean_img)\n","            np.save(std_img_path, std_img)\n","            exit(0)\n","        else:\n","            mean_img = np.load(mean_img_path)\n","            std_img = np.load(std_img_path)\n","            assert((mean_img is not None) and (std_img is not None))\n","            x_train, y_train = self.read_dir(os.path.join(in_dir, 'TRAIN'), id2cell, (mean_img, std_img))\n","            x_test, y_test = self.read_dir(os.path.join(in_dir, 'TEST'), id2cell, (mean_img, std_img))\n","\n","            x_train, x_validation, y_train, y_validation = \\\n","                train_test_split(x_train, y_train, test_size=self.vld_portion, random_state=42, stratify=y_train)\n","\n","        return x_train, x_validation, x_test, y_train, y_validation, y_test\n","\n","\n","    class DataError(Exception):\n","        \"\"\" Base class for all exceptions \"\"\"\n","        pass\n","\n","    class DataInitError(DataError):\n","        \"\"\" Initialization failed \"\"\"\n","        pass\n","\n","    class DataBatchError(DataError):\n","        \"\"\" Failed while getting next batch \"\"\"\n","        pass\n","\n","\n","\n","\n","#----------------------------------------------MAIN---------------------------------------------------------------------------------------------\n","import os\n","from datetime import datetime\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","my_random_seed = 1337\n","np.random.seed(my_random_seed)\n","tf.set_random_seed(my_random_seed)\n","\n","from keras.models import Model, load_model\n","from keras.layers import Input, Conv2D, Dense, Flatten, Dropout, BatchNormalization, Activation\n","from keras.optimizers import Adam, Adadelta, Adagrad, RMSprop\n","from keras.callbacks import ModelCheckpoint\n","from keras import regularizers\n","\n","this_path = '/content/drive/My Drive/Colab Notebooks/'\n","\n","\n","def get_model(out_ht, out_wd, model_id):\n","    inputs = Input(shape=(out_ht, out_wd, 3))\n","    if model_id == '0':\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n","        x = Flatten()(x)\n","        x = Dense(128, activation='relu')(x)\n","        x = Dense(128, activation='relu')(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '1':\n","        # Ran for 100 epochs: Shows overfitting. best validation accuracy: 78%\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '2_0':\n","        # L2 regularization\n","        # It does slow down the overfitting but validation accuracy gets stuck at ~60%\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu', kernel_regularizer=regularizers.l2())(inputs)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu', kernel_regularizer=regularizers.l2())(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu', kernel_regularizer=regularizers.l2())(x)\n","        x = Dense(8, activation='relu', kernel_regularizer=regularizers.l2())(x)\n","        x = Dense(4, activation='softmax', kernel_regularizer=regularizers.l2())(x)\n","    elif model_id == '2_1':\n","        # L1 regularization\n","        # Accuracy of training and validation got stuck at 25%\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu', kernel_regularizer=regularizers.l1())(inputs)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu', kernel_regularizer=regularizers.l1())(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu', kernel_regularizer=regularizers.l1())(x)\n","        x = Dense(8, activation='relu', kernel_regularizer=regularizers.l1())(x)\n","        x = Dense(4, activation='softmax', kernel_regularizer=regularizers.l1())(x)\n","    elif model_id == '3_0':\n","        # Have dropout\n","        # No overfitting. training loss was still decreasing. train acc: 70%, val_acc: 75%\n","        # Need more epochs\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '3_1':\n","        # Batch normalization\n","        # Could not prevent from overfitting. Train acc: 93% val acc 70%\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same')(inputs)\n","        x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same')(x)\n","        x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = Flatten()(x)\n","        x = Dense(16)(x)\n","        x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = Dense(8)(x)\n","        x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '3_2':\n","        # Batch normalization + Dropout\n","        # Faster convergence. Has overvitting. train acc 82% val acc 66%\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same')(inputs)\n","        x = Activation('relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Activation('relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(16)(x)\n","        x = Activation('relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(8)(x)\n","        x = Activation('relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '10_0':\n","        # 3_0 with more epochs\n","        # No overfitting. train acc: 70%, val_acc: 75%\n","        # It gets hard to get more gains beyond it\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        # x = Dense(8, activation='relu')(x)\n","        # x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '20_0':\n","        # Reducing the stride on conv layers\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n","        # x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        # x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        # x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu')(x)\n","        # x = Dropout(0.2)(x)\n","        x = Dense(8, activation='relu')(x)\n","        # x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '20_1':\n","        # 20_0 with dropout\n","        # Achieves 88% val accuracy in ~100 epochs\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '20_2':\n","        # Increase model complexity with Dropout\n","        # 88% val_acc in 80 epochs\n","        # 95% val_acc in 200 epochs\n","        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(32, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '20_3':\n","        # Reduce the kernel size from 5 to 3\n","        # val acc is lower than with kernel 5\n","        x = Conv2D(4, 3, strides=(2, 2), padding='same', activation='relu')(inputs)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 3, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 3, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '20_4':\n","        # 20_2 with BatchNorm for faster convergence\n","        # Gives 97% accuracy. Model saved as model_20_4_e1000.h5\n","        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(32, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '100_0':\n","        # A low capacity model\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '100_1':\n","        # A low capacity model with dropout to show that capacity isn't enough\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(inputs)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(4, 4), padding='same', activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '100_2':\n","        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n","        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = Flatten()(x)\n","        x = Dense(32, activation='relu')(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '100_3':\n","        # 100_2 with Dropout\n","        pass  # Same as 20_2\n","    elif model_id == '100_4':\n","        # 100_3 with BatchNormaliation\n","        # 20_2 with BatchNorm for faster convergence\n","        # Gives 97% accuracy. Model saved as model_20_4_e1000.h5\n","        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(0.2)(x)\n","        x = Flatten()(x)\n","        x = Dense(32, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id in ('100_5_0', '100_5_1', '100_5_2'):\n","        # Effect of dropout amount\n","        if model_id == '100_5_0':\n","            dropout = 0.1\n","        elif model_id == '100_5_1':\n","            dropout = 0.2\n","        elif model_id == '100_5_2':\n","            dropout = 0.3\n","        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Flatten()(x)\n","        x = Dense(32, activation='relu')(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id in ('100_6_0', '100_6_1', '100_6_2', '100_6_3'):\n","        dropout = 0.2\n","        # Effect of optimizers\n","        if model_id == '100_6_0':\n","            opt = Adam()\n","        elif model_id == '100_6_1':\n","            opt = Adadelta()\n","        elif model_id == '100_6_2':\n","            opt = Adagrad()\n","        elif model_id == '100_6_3':\n","            opt = RMSprop()\n","        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation='relu')(inputs)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='relu')(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Flatten()(x)\n","        x = Dense(32, activation='relu')(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(16, activation='relu')(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(8, activation='relu')(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(4, activation='softmax')(x)\n","\n","        outputs = x\n","        m = Model(inputs=inputs, outputs=outputs)\n","        print(m.summary())\n","        m.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","        return m\n","    elif model_id in ('100_7_0', '100_7_1', '100_7_2'):\n","        # Effect of activation function\n","        dropout = 0.2\n","        if model_id == '100_7_0':\n","            act_fn = 'sigmoid'\n","        elif model_id == '100_7_1':\n","            act_fn = 'tanh'\n","        elif model_id == '100_7_2':\n","            act_fn = 'relu'\n","        x = Conv2D(16, 5, strides=(2, 2), padding='same', activation=act_fn)(inputs)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(8, 5, strides=(2, 2), padding='same', activation=act_fn)(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation=act_fn)(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, 5, strides=(2, 2), padding='same', activation=act_fn)(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Flatten()(x)\n","        x = Dense(32, activation=act_fn)(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(16, activation=act_fn)(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(8, activation=act_fn)(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id in ('100_8_0', '100_8_1'):\n","        # Effect of Conv filter size\n","        dropout = 0.2\n","        act_fn = 'relu'\n","        if model_id == '100_8_0':\n","            filter_size = 3  # 3x3\n","        elif model_id == '100_8_1':\n","            filter_size = 5  # 5x5\n","        x = Conv2D(16, filter_size, strides=(2, 2), padding='same', activation=act_fn)(inputs)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(8, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Flatten()(x)\n","        x = Dense(32, activation=act_fn)(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(16, activation=act_fn)(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(8, activation=act_fn)(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(4, activation='softmax')(x)\n","    elif model_id == '100_9_0':\n","        # This could be the best model based on hyperparameters experimentation\n","        # Nope: overfits slightly faster than validation loss\n","        dropout = 0.1\n","        act_fn = 'tanh'\n","        filter_size = 5\n","        opt = Adam()\n","        x = Conv2D(16, filter_size, strides=(2, 2), padding='same', activation=act_fn)(inputs)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(8, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Conv2D(4, filter_size, strides=(2, 2), padding='same', activation=act_fn)(x)\n","        x = BatchNormalization()(x)\n","        x = Dropout(dropout)(x)\n","        x = Flatten()(x)\n","        x = Dense(32, activation=act_fn)(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(16, activation=act_fn)(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(8, activation=act_fn)(x)\n","        x = Dropout(dropout)(x)\n","        x = Dense(4, activation='softmax')(x)\n","\n","        outputs = x\n","        m = Model(inputs=inputs, outputs=outputs)\n","        print(m.summary())\n","        m.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","        return m\n","\n","    outputs = x\n","    m = Model(inputs=inputs, outputs=outputs)\n","    print(m.summary())\n","\n","    opt = RMSprop()\n","    m.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return m\n","\n","\n","def main():\n","    batch_size = 128\n","    epochs = 30 #1000\n","    model_list = ['100_4']\n","    create_stat_image = False\n","\n","    resource_dir = os.path.join(this_path, 'models')\n","    #os.makedirs(resource_dir, exist_ok=True)\n","\n","    try:\n","        data = Data(batch_size)\n","    except Data.DataInitError as e:\n","        print('Failed to initialize Data instance.\\n{:s}'.format(str(e)))\n","        return\n","\n","    if 1:  # Training\n","        for model_id in model_list:  # Training\n","            model_path = os.path.join(resource_dir, model_id + '_model.h5')\n","            cb_save = ModelCheckpoint(model_path, monitor='val_loss', verbose=0, save_best_only=True)\n","            m = get_model(data.out_ht, data.out_wd, model_id)\n","\n","            print('############### Training Model ID: {:s} #####################'.format(model_id))\n","            m.fit_generator(data.get_batch('TRAIN'),\n","                            steps_per_epoch=data.steps_per_epoch,\n","                            epochs=epochs,\n","                            validation_data=data.get_batch('VALIDATION'),\n","                            validation_steps=data.validation_steps,\n","                            shuffle=False,\n","                            callbacks=[cb_save])\n","\n","    if 0:  # Testing\n","        model_path = os.path.join(resource_dir, '20_2_model_e1000.h5')\n","        m = load_model(model_path)\n","        eval_out = m.evaluate_generator(data.get_batch('TRAIN'),\n","                                        steps=data.test_steps)\n","        print('Train error: ', eval_out)\n","\n","        eval_out = m.evaluate_generator(data.get_batch('VALIDATION'),\n","                                        steps=data.test_steps)\n","        print('Validation error: ', eval_out)\n","\n","        eval_out = m.evaluate_generator(data.get_batch('TEST'),\n","                                        steps=data.test_steps)\n","        print('Test error: ', eval_out)\n","\n","\n","if __name__ == '__main__':\n","    main()\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 120, 160, 3)       0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 60, 80, 16)        1216      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 60, 80, 16)        64        \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 60, 80, 16)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 30, 40, 8)         3208      \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 30, 40, 8)         32        \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 30, 40, 8)         0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 20, 4)         804       \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 15, 20, 4)         16        \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 15, 20, 4)         0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 8, 10, 4)          404       \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 8, 10, 4)          16        \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 8, 10, 4)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 320)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 32)                10272     \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 16)                528       \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 16)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 8)                 136       \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 8)                 0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4)                 36        \n","=================================================================\n","Total params: 16,732\n","Trainable params: 16,668\n","Non-trainable params: 64\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","############### Training Model ID: 100_4 #####################\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/30\n","15/53 [=======>......................] - ETA: 1:38 - loss: 1.9968 - acc: 0.2411"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:709: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n","  UserWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rTILc852KGgJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8120b786-8b44-4792-92e5-eb3e2b47fd9b","executionInfo":{"status":"ok","timestamp":1572532847600,"user_tz":-60,"elapsed":2774,"user":{"displayName":"Ilona T","photoUrl":"","userId":"06637132191872925947"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sS2TqiJ3KIOI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"bd35873d-3bb0-4616-9d99-ff8af2b5fb9e","executionInfo":{"status":"ok","timestamp":1572532849243,"user_tz":-60,"elapsed":691,"user":{"displayName":"Ilona T","photoUrl":"","userId":"06637132191872925947"}}},"source":["cd /content/drive/My\\ Drive/Colab\\ Notebooks"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xk-RucibNSJj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"07f555cf-cc3a-44e5-efc7-ea6506e7bc59","executionInfo":{"status":"ok","timestamp":1572532851492,"user_tz":-60,"elapsed":724,"user":{"displayName":"Ilona T","photoUrl":"","userId":"06637132191872925947"}}},"source":["pwd"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Colab Notebooks'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"CWZ05_4gKKCv","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/')"],"execution_count":0,"outputs":[]}]}